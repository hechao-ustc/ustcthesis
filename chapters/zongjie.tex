% !TeX root = ../main.tex

\chapter{系统总结与展望}

本章主要对数据湖分析系统的设计与开发过程做出总结，并对未来的工作提出展望。

\section{总结}

随着企业对数据驱动业务需求的深入，也随着海量数据分析技术的成熟，
数据仓库已是企业内部进行数据洞察的标准服务。但是传统基于Hadoop
技术的数据仓库从数据导入到数据分析每个环节都有较大的延迟，使得数
据分析的时效性大大变低；同时对于数据分析场景的拓展，传统单一的数
仓架构也没法满足多变的数据分析需求。
现如今Hadoop生态圈的数据仓库大多面向的是离线场景，数据从接入直到展示
存在着小时级以上的延迟，这其中一方面是因为批处理框架本身延迟的限制，
另一方面也是因为对于变化数据捕捉能力的缺失。
为此业界也在探索新一代更为通用的架构，
而现有的Lambda架构和Kappa架构，
有着维护困难、灵活性较低、消息中间件回放困难、无法利用到传统数仓的优化技术等缺点。
为了解决上面的缺点，引入了新型的数据组织格式Iceberg，并依托Oceanus（基于Flink的流式计算平台）
、US（基于spark的统一调度平台）和已有的交互式查询引擎Presto加上SuperSQL的能力，打造下一代的实时湖仓——数据湖分析系统。

数据湖分析系统是一个基于Iceberg的数据分析平台，它可以帮助组织和
企业快速存储、处理和分析大规模数据。以下是数据湖分析系统的特点：

（1）T+0接入。利用Flink和Iceberg在Oceanus平台可以实现准实时的数据接入，
Iceberg提供秒级至分钟级的延迟能力，结合Flink可以准实时地将数据写入数据湖Iceberg表中，供下游业务方进一步加工处理。

（2）批流融合。Iceberg提供了基于流式的增量计算模型和基于批处理的全量表计算模型，
因此在构建数据分析架构时不再需要为流式计算和批处理配备不同的存储服务，
可以使用统一的分布式存储系统（HDFS，Ozone，COS）来存储数据，提供两种不同的计算模型，实现批流融合。
这样带来了几个好处：一是所有的数据从原始导入数据到最后展示的报表都是存储在了同一个存储中，
这自然地就构建起了数据湖，无须像Lambda架构那样维护多个不同的存储；
二是由于所有的数据都是在一个统一的存储中，因此数据的管理、回溯、可靠性得到了很好的保障，
有效地提升了作业的可靠性。同时也大大增加了灵活性，用户可以根据需求适时调整查询，
因为全量数据都是存在Iceberg表中，而不像Kappa架构只维护了一定时间段的数据；
三是由于Iceberg底层是按照列式存储存在分布式存储上的，因此可以使用到引擎所有的优化手段，
包括谓词下推、向量化等能力。相比于上面的Kappa架构利用消息中间件来回放数据，性能上会有非常大的提升。

（3）秒级分析。借助于优越的跨引擎计算能力，SuperSQL已支持将SQL计算交由Presto完成，
满足通用的秒级湖仓分析需求。通过整合Presto和Iceberg的能力，能够在海量数据上进行实时的交互式查询，提升了整体业务转化的效率。

（4）事务语义。Iceberg提供了事务语义和基于快照的读写分离能力，因此它具备一定的并发性，
对于上游T+0写入的数据下游可以立马消费到，大大降低了端到端的时延，同时也提供了更为一致的语义保证。
同时基于Iceberg所提供的事务能力，Iceberg提供了行级的Update、Delete、Upsert语义，
这极大地降低了数据修改的成本。对于延迟数据的补全，或是错误数据的事后修复，
可以使用很小的代价(copy-on-write和merge-on-read)实现，极大地降低了数据修复的成本，提升了数据的可用性。
同时利用Upsert语义的支持，Flink+Iceberg可以很好地支持增量数据入湖（Change Data Capture）的场景，
能以很小的代价将业务数据库中的数据实时汇总到数仓接入层。

（5）数据自动优化。帮助用户一键式优化，使用户无需关心Iceberg的维护。
当前服务包括小文件合并、历史元数据清理、孤儿文件删除、数据生命周期管理。

（6）支持分析工具集成。数据湖分析系统可以与多种分析工具进行集成，
包括数据可视化工具、商业智能工具和机器学习平台等，以满足不同用户和业务部门的需求。

目前，DLA已上线并提供了一站式数据入湖服务，将数据导入时延从天级别降至分钟级别，
数据查询时延从分钟级别降至秒级查询，整体端到端的数据展示时间缩短至分钟级。此外，
DLA还对接了企业内部的大数据计算平台、数据查询平台和报表平台等多个下游业务系统，创造了巨大的价值。

综上所述，DLA可以提供大规模数据处理和分析的能力，支持组织和企业实现数据驱动的决策，并为业务增长提供支持。

\section{展望}

尽管数据湖分析系统已上线，为企业用户提供了稳定可靠的一站式数据入湖服务，
但随着大数据领域的发展，未来将有更多应用场景和技术挑战。
为满足企业未来业务需求，数据湖分析系统还有很多的工作需要做。

在架构方面，进一步加速湖仓分析能力，引入Alluxio分布式缓存系统来进一步加速数据查询，使得查询速度有进一步的提升；
进一步加强增量数据入湖能力，利用Flink CDC、Debezium，Canal等新型CDC技术，进一步增强Iceberg流式增量接入的能力，
能做到对于变化数据的准实时接入。

在Iceberg方面，加入索引和CBO（Cost-Based Optimizer）。
传统的数仓比较少使用索引服务，有一些考虑是因为索引建立的成本比较大，特别是聚簇索引，
不仅会影响写入的吞吐量，也会加大存储和计算的成本。
然而越来越多的业务场景提出对实时数据分析需求，例如，广告效果转化，反欺诈业务等，
这些场景要求它们的分析型任务能够在分钟级别返回结果。
Iceberg社区针对索引的需求设计了一种专门用于索引的格式puffin format, 目前puffin会用来存储一些统计信息。
可以预计未来会有越来越多的索引在puffin实现，比如Min-Max索引、Bloom Filter索引、BitMap索引、Bucket索引等等。
除了索引，利用puffin format，还可以加入CBO，即基于代价的优化器。
CBO是一种查询优化器，可以帮助优化查询语句的执行计划，从而提高查询效率。在关系数据库中，
查询语句通常由多个表进行join操作，CBO可以通过考虑每个可能的join执行计划的代价
（例如I/O操作、内存开销等），选择代价最小的执行计划来优化查询性能。

在系统集成方面。目前内部也引入了Apache Hudi，
Hudi（Hadoop Upserts, Deletes, and Incrementals）旨在
为大规模数据湖提供最佳性能和易用性。 它通过支持时间旅行和增量数
据更新（Upsert）以及数据删除，可以减少数据湖的成本和复杂性。
此外，Hudi还支持流数据和批数据，并提供了强大的CDC功能。
但目前用户使用Hudi必须自己手写程序和手动维护，这对用户来说是不小的成本。
所以下一步可以把Hudi集成到数据湖分析系统中去，帮助用户能够轻松的使用Hudi。

在自动优化服务方面，加入自动创建索引和列的生命周期管理。通过自动创建索引，可以加速查询操作的执行速度，减少查询时间，
自动创建索引可以减少数据管理员手动维护索引的工作量，降低管理成本，
通过自动创建索引，可以根据查询模式和查询频率动态地调整索引的创建和删除策略，以适应数据查询的变化。
Iceberg表在业务中有许多都是大宽表，大宽表通常包含许多列，其中一些列可能很少使用，
通过删除不必要的列，可以减少表格占用的存储空间，提高空间效率。
列的生命周期管理可以帮助优化表格的查询性能，例如，删除不必要的列可以减少查询时间，而添加索引列可以加速查询操作的执行速度。
自动化列的生命周期管理可以减少数据管理员的工作量，降低管理成本。

在功能拓展方面，为系统添加数据治理。数据治理是指对数据进行规划、管理和监控的过程，目的是确保数据的质量、
完整性和合规性。通过数据治理管控，可以确保数据的质量和完整性，避免数据失真和错误。
数据治理管控可以帮助保护数据的安全性，确保敏感数据不被非法获取和滥用。
通过数据治理管控，可以确保数据的合规性，避免违反法规和标准。
因此，在数据自动优化服务中加入数据治理管控是非常必要的。
