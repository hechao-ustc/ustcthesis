% !TeX root = ../main.tex

\chapter{系统需求分析}

本章主要介绍数据湖分析系统的需求分析过程，主要包括系统概述、功能性
需求分析、非功性需求分析三部分。针对公司目前面临的挑战和业务痛点，梳理业
务流程，确定项目需求。然后将需求划分为不同的模块，确定不同模块包含的功能
点，进行用例图展示，为后续的系统设计以及开发测试工作奠定基础。

\section{系统概述}

虽然数据湖在企业内部的需求很高，但客户使用的门槛较高，需要根据Apache Iceberg
官网的教程编写java程序来实现数据的入湖或者读取，这就对不太熟悉java的客户来说
不太友好，并且Iceberg后续的运维成本对于客户来说也比较高。因此，我们开发了数据
湖分析系统，数据湖分析系统可以轻松完成T+0实时入湖，支持批流融合、秒级分析、事务语义、挖掘和探索数据价值等。

数据湖分析系统底层基于Apache Iceberg作为数据湖载体，开发框架使用Spring Boot，包含数
据源管理、元数据管理、数据入湖、数据探索、自动优化服务五大模块，其中自动优化服务是通过
内部调研发现，用户认为iceberg的运维成本较高，学习成本较大，所以设计了数据自动优化服务，帮助用户一键式优化。
并且我们还在Iceberg侧实现了小文件合并优化的功能，不但减少了小文件的数量增强了Iceberg的查询能力，而且还降低了用户的运维成本。

\section{系统功能性需求}

上一小节系统概述中，将数据湖分析系统划分为五大模块，在本节中将针对每一个模块进行详细分析。

\subsection{数据源管理模块}

数据源是入湖任务的前提要求，注册相应数据源，创建入湖任务时即可根据创建的数据源选择对应的源表。
数据源管理模块主要对数据源进行管理，其中关系型数据库支持Mysql，消息队列数据源支持Tube、Kafka、
Pulsar[17]等数据源；支持数据源创建、查看、编辑、删除功能。数据源管理模块的需求用例图如图3.1所示：

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{数据源用例图.png}
  \caption{数据源管理模块用例图}
  \label{fig:badge}
\end{figure}

\subsection{元数据管理模块}

元数据（Metadata）是描述其它数据的数据（data about other data）[15]，
或者说是用于提供某种资源的有关信息的结构数据（structured data）。元数据是
描述信息资源或数据等对象的数据，其使用目的在于：识别资源；评价资源；追踪资源
在使用过程中的变化；实现简单高效地管理大量网络化数据；实现信息资源的有效发现、查找、一体化组织和对使用资源的有效管理。

这里的元数据是描述iceberg表的，iceberg表即目标表，是入湖任务的前提要求，
可以创建新表或者关联已有的表，在创建入湖任务时即可选择对应的目标表。元数据管
理模块主要对iceberg元数据进行管理，包含四个主要的功能，分别是数据自动优化、表的
创建、表的编辑、表的查看。其中数据优化功能会在后面进行详细介绍，表的创建既可以在数据湖分析系统上创建
新的iceberg表，也可以关联在其它平台上已创建的iceberg表；表的编辑可以将创建过
的表进行修改编辑，支持字段的增加及删除操作。元数据管理模块的需求用例图如图3.2所示：

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{元数据用例图.png}
  \caption{元数据管理模块用例图}
  \label{fig:badge}
\end{figure}

\subsection{数据入湖模块}

数据入湖功能模块是数据湖分析系统核心流程功能，目的是用户通过该功能将源数据表流程化入湖和查看
已申请入湖任务执行情况，目前支持的入湖类型为实时入湖（tube入湖、kafka入湖、pulsar入湖）
、存量入湖（data warehouse数据入湖）、关系型数据库入湖（mysql全量入湖、mysql增量入湖）。
其中实时入湖就是流形式的入湖，底层使用的flink来实现的；存量入湖就是批形式的入湖，底层使用的
spark来实现的；关系型数据入湖是指数据源是mysql，有全量、增量两种方式，全量就是只执行一次，
增量就是需要设置时间间隔、起始时间来定时更新。数据入湖模块的需求用例图如图3.3所示：

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{数据入湖用例图.png}
  \caption{数据入湖模块用例图}
  \label{fig:badge}
\end{figure}

创建入湖任务总共需要五步：

（1）填写基础信息，根据入湖需要选择对应的入湖分类，填写必要的任务名；

（2）填写源表，实时入湖与关系型数据库入湖需要提前注册数据源，选择对应数据源表；

（3）填写目标表，所有入湖任务基本一致，支持推荐Schema功能，无需提前新建表，若目标表未创建，则任务创建时会自动的创建与源表对应的目标表，简化了创建目标表流程；

（4）查看映射预览，对源表及目标表schema映射展示，schema不一致无法进行下一步；

（5）填写参数及资源，对任务的资源进行配置。

\subsection{数据探索模块}

数据探索是数据入湖后，用户可以使用Spark、Presto、Zeppelin等引擎来进行查询分析数据，以实现数据的价值。

Spark和Presto都是通过写SQL作业来完成数据的查询分析，Presto的查询能力(select能力)突出，
可以实现秒级查询，但是Presto仅支持查询，其它的语句都不支持，相对的Spark的查询能力一般，
但是Spark支持的语句比较多，创建表、删除表、更新表、数据写入、数据删除、更新分区、表维护等
语句都是支持的。用户可以结合实际的情况灵活使用。

Zeppelin是一个基于Web的notebook，提供交互数据分析和可视化。后台支持接入多种数据处理引擎，
如spark，hive等。支持多种语言： Scala(Apache Spark)、Python(Apache Spark)、
Spark SQL、 Hive、 Markdown、Shell等。开发者可以通过实现更多的解释器来为Zeppelin添加数据引擎。

\subsection{自动优化服务}

当前Iceberg运维有以下缺点：
用户需自行写java程序维护；
用户估计经验值，设定资源，资源浪费，或者不足导致失败；
若合并频率低，小文件多，则查询效率低，查询消耗资源多，合并频率高，可能导致重复合并，无法在适当的时间合并；
分区间数据不均衡时，无法按照分区合并，导致某些数据较少的分区被重复合并；
需持续观察任务执行情况，判断是何种原因导致失败，无告警；
为了解决这些缺点我们设计了数据自动优化服务，包括小文件合并、历史快照清理、孤儿文件删除、数据生命周期管理等服务。
其功能结构图如图3.4所示。自动优化服务有以下优点：
一键启动优化服务；
根据表的若干指标及历史执行情况判断所需资源；
合并恰如其时，根据写入的数据量判断合并的频次，查询速度稳定加快；
按照分区合并，仅合并需要合并的分区；
告警机制，专业运维及时处理；

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{数据优化服务功能结构图.png}
  \caption{数据优化服务功能结构图}
  \label{fig:badge}
\end{figure}

\subsubsection{小文件合并}

由于hadoop一次写入，不可更改的特性，Iceberg写入会产生若干小文件，
尤其是在分区较多，并发写入较大的情况下，会加剧小文件数量，对HDFS NameNode造成压力，造成用户查询速度较慢。
将海量⼩⽂件进⾏合并为⼤⽂件，既可以提高查询效率降低数据存储成本，也能降低存储系统的元数据管理的压力。

由于原有的Iceberg小文件合并在我们的实际应用中有着诸多的问题，比如合并不及时、浪费资源、
合并资源占用计算资源过多的问题。基于以上问题，我们重新设计了小文件合并规则。

关于小文件合并，我们最初是通过在Flink Sink后接入Compaction Operator
的方式来进行在线的小文件合并，但随后发现在生产过程中存在很多的问题，最显著的就是
资源占用。因为其合并的任务逻辑属于Flink任务的一部分，需要占用Flink集群资源。
因此我们通过数据自动优化服务来定期进行Iceberg表的compaction操作（生成saprk
任务来进行compaction）。然而定期调度存在对文件状态不确定，即不明确何时合并，
是否小文件过多，这样就可能存在调度起了一个合并任务，但是任务执行只发现了2个小文件，
因为在这个定时的区间内只有两个小文件生成。如图3.7所示，定时调度任务每次执行的文件数非常不均衡。

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{小文件合并定时任务调度.png}
  \caption{定时任务调度合并文件数量}
  \label{fig:badge}
\end{figure}

如图3.8所示，两个任务分别合并了2个和7个小文件，而理想的状况是一个任务合并9个小文件，
该问题的核心点在于合并的任务无法知道当前的文件状态，因此需要一种计算规则来判断当前
一个区间内是否达到了发起合并任务的时刻，即需要计算出文件的状态，以作为合并任务调度的合并规则。

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{小文件合并定时任务调度2.png}
  \caption{小文件合并理想示意图}
  \label{fig:badge}
\end{figure}

\subsubsection{历史快照清理}

由于Iceberg提供了time travel功能，所以元数据和数据文件会保留每条记录的多个版本快照（snapshot），
并且合并小文件时也会产生新的snapshot，但此时无用的小文件不会被立即删除。
如图3.9所示，DataFile A和DataFile B，进行Rewrite后，生成了DataFile C，但这里A和B已经是重复的数据了，
可以删除了。所以我们添加了历史快照清理，来清除这些不需要的数据。

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{历史快照删除场景.png}
  \caption{历史快照删除场景}
  \label{fig:badge}
\end{figure}

\subsubsection{孤儿文件删除}

有的时候计算引擎执行任务失败，会产生一些不被引用的data和metadata files,
还有当rewrite失败或者commit失败时也会产生若干没有被引用的文件，这些文件都是孤儿文件，需要进行定期清理。
如图3.10所示，当commit冲突或者rewrite失败时，期间产生的新的文件DataFile C就变成了
孤儿文件，需要进行清理。

\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{孤儿文件产生场景.png}
  \caption{孤儿文件产生场景}
  \label{fig:badge}
\end{figure}

\subsubsection{数据生命周期管理}

为了更好的管理iceberg数据同时也为了节约用户成本，对数据的生命周期进行管理就显得尤为重要。
对数据进行生命周期管理，需要所创建的表中带有Date或TimeStamp类型的时间字段，并对此字段进行
操作删除过期数据。

\section{系统非功能性需求}

（1）界面交互无障碍。系统应当提供给用户友好的交互界面，搭配各项可视化展示与适当的提示，提供给用户良好的服务使用体验；

（2）操作易用性。操作易用性要求软件开发时要减少不必要的操作步骤，方便用户的使用，采用高效的缓存机制，减少用户输入信息次数；

（3）系统安全性要求。系统安全性要求系统具备严格的权限访问控制机制，用户鉴权认证登录后，能够访问与之权限相对应的数据，只能使用其权限范围内的功能。另外要设置系统运行日志管理功能，及时发现运行过程中的问题；

（4）异常检测与系统可用性。由于要防止瞬时流量较高或者某个服务的波动引起的异常，系统需要有异常快速检测与上报功能，异常严重时还需要进行告警，保证系统整体可用；

（5）运行高效性。高效性是指系统在运行过程中的响应时间问题上，如登录时间、页面跳转时间、查询时间、页面刷新时间要短，非发起审核接口要在 1000ms 内相应，大规模数据地加载要在 2000ms 内完成；

（6）系统易维护性。在系统出现故障或者需要修改时要便于发现故障和判断需要修改部分所在位置，在修改时不会因局部的变动导致代码大篇算幅修改，最后是系统部署时间要短，将更多的时间用于开发；

（7）系统可移植性。可移植性要求系统对运行环境的适应性较强。所以在开发时要选用通用的程序设计语言，大部分系统都能够兼容的开发工具、数据库、插件；在界面设计时，要使用根据设备屏幕自适应的前端框架。

\section{本章小结}

在本章中首先对系统进行整体概述，明确项目目标以及应该具备的核心功能。
然后对数据源模块管理、元数据模块管理、数据入湖管理模块、数据探索模块、自动优化服务五方面详细
描述系统的功能性需求。最后从系统性能需求、可用性、易用性等方面对系统的非功能性需求进行阐述。
